import pandas as pd
import argparse
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
from sklearn.preprocessing import LabelBinarizer

# ðŸ“¥ Argumentos desde la terminal
parser = argparse.ArgumentParser(description="Entrenar modelo de detecciÃ³n de estrÃ©s tÃ©rmico.")
parser.add_argument('--dataset', type=str, required=True, help="Ruta del archivo CSV")
args = parser.parse_args()

# ðŸ“Š Cargar datos
df = pd.read_csv(args.dataset)

# ðŸ•’ Procesar columna timestamp
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['hora'] = df['timestamp'].dt.hour
df['dia_semana'] = df['timestamp'].dt.dayofweek
df['mes'] = df['timestamp'].dt.month
df = df.drop(columns=['timestamp'])

# ðŸŽ¯ Separar X (caracterÃ­sticas) y y (etiqueta)
X = df.drop(columns=['estres_termico'])
y = df['estres_termico']

# ðŸ”€ Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ðŸŒ² Entrenar modelo
modelo = RandomForestClassifier(n_estimators=100, random_state=42)
modelo.fit(X_train, y_train)

# ðŸ’¾ Guardar modelo entrenado
with open("modelo_entrenado.pkl", "wb") as f:
    pickle.dump(modelo, f)

# ðŸ“ˆ Evaluar
y_pred = modelo.predict(X_test)
y_proba = modelo.predict_proba(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"âœ… Accuracy: {accuracy:.4f}")

print("\nðŸ“‹ Reporte de ClasificaciÃ³n:")
print(classification_report(y_test, y_pred))

print("ðŸ“‰ Matriz de ConfusiÃ³n:")
print(confusion_matrix(y_test, y_pred))

# ðŸŽ¯ ROC AUC Score con codificaciÃ³n one-hot
lb = LabelBinarizer()
y_test_bin = lb.fit_transform(y_test)
roc_auc = roc_auc_score(y_test_bin, y_proba, multi_class='ovr')
print(f"\nðŸŽ¯ ROC AUC Score: {roc_auc:.4f}")
